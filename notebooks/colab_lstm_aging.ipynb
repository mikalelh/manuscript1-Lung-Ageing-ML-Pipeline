{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run LSTM aging model on Google Colab (GPU)\n",
        "\n",
        "This notebook runs the **Ageing in the Lung** LSTM model in Colab with free GPU.\n",
        "\n",
        "**Important:** Before running anything:\n",
        "1. **Runtime → Change runtime type → Hardware accelerator → GPU** (e.g. T4) → Save.  \n",
        "   If you see \"Device: cpu\", the runtime is not set to GPU — change it and re-run from the top.\n",
        "2. Run cells in order.\n",
        "3. Upload `discovery_combined.h5ad` via the upload cell (large files can break if dragged; use the file picker)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Clone repo and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Detect Colab vs local run; set repo root\n",
        "import os\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    REPO_ROOT = \"/content/msl_aging_pipeline\"\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    cwd = os.getcwd()\n",
        "    REPO_ROOT = os.path.dirname(cwd) if os.path.basename(cwd) == \"notebooks\" else cwd\n",
        "print(\"Colab:\", IN_COLAB, \"| REPO_ROOT:\", REPO_ROOT)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab: False | REPO_ROOT: /home/melhajjar/ipython_notebooks/manuscript1_ageing_inthelung/msl_aging_pipeline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if IN_COLAB:\n",
        "    !git clone https://github.com/mikalelh/manuscript1-Lung-Ageing-ML-Pipeline.git {REPO_ROOT} 2>/dev/null || (cd {REPO_ROOT} && git pull)\n",
        "%cd {REPO_ROOT}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: /content/msl_aging_pipeline: No such file or directory\n",
            "[Errno 2] No such file or directory: '/content/msl_aging_pipeline'\n",
            "/home/melhajjar/ipython_notebooks/manuscript1_ageing_inthelung/msl_aging_pipeline/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip3 install -q scanpy anndata pandas scikit-learn tqdm matplotlib\n",
        "import torch\n",
        "cuda_ok = torch.cuda.is_available()\n",
        "print('CUDA available:', cuda_ok)\n",
        "if cuda_ok:\n",
        "    print('Device:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('WARNING: No GPU detected. For faster training: Runtime → Change runtime type → Hardware accelerator → GPU → Save, then re-run from the top.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Add data: upload or Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Option A: Upload discovery_combined.h5ad (Colab only; run this cell, then use the file picker)\n",
        "import os\n",
        "import shutil\n",
        "data_dir = os.path.join(REPO_ROOT, \"data\")\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for name in uploaded:\n",
        "        shutil.move(name, os.path.join(data_dir, \"discovery_combined.h5ad\"))\n",
        "    print(\"Saved to data/discovery_combined.h5ad\")\n",
        "else:\n",
        "    print(\"Local run: put discovery_combined.h5ad in\", data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Use .h5ad from repo root or data/ — ensure it's in data/ so the script finds it\n",
        "import os\n",
        "import shutil\n",
        "data_dir = os.path.join(REPO_ROOT, \"data\")\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "target = os.path.join(data_dir, \"discovery_combined.h5ad\")\n",
        "in_root = os.path.join(REPO_ROOT, \"discovery_combined.h5ad\")\n",
        "if os.path.isfile(in_root):\n",
        "    shutil.copy2(in_root, target)\n",
        "    print(\"Copied discovery_combined.h5ad from repo root → data/\")\n",
        "if os.path.isfile(target):\n",
        "    print(\"Ready: data/discovery_combined.h5ad\")\n",
        "else:\n",
        "    print(\"Put discovery_combined.h5ad in the repo root (or in data/), then re-run this cell.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Option B: Use a file already on Google Drive (uncomment and set path)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# import shutil\n",
        "# shutil.copy('/content/drive/MyDrive/path/to/discovery_combined.h5ad', '/content/msl_aging_pipeline/data/discovery_combined.h5ad')\n",
        "# print('Copied from Drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Validate discovery h5ad before running LSTM (avoids \"file signature not found\" later)\n",
        "import os\n",
        "data_dir = os.path.join(REPO_ROOT, \"data\")\n",
        "path = os.path.join(data_dir, \"discovery_combined.h5ad\")\n",
        "if not os.path.isfile(path):\n",
        "    print(\"ERROR: File not found:\", path)\n",
        "    print(\"Upload discovery_combined.h5ad (Option A cell) or copy from repo root/Drive, then re-run the data cells.\")\n",
        "else:\n",
        "    size_mb = os.path.getsize(path) / (1024 * 1024)\n",
        "    print(f\"File size: {size_mb:.1f} MB\")\n",
        "    try:\n",
        "        import scanpy as sc\n",
        "        adata = sc.read_h5ad(path)\n",
        "        print(\"OK: Valid h5ad. Cells:\", adata.n_obs, \"| Genes:\", adata.n_vars)\n",
        "    except OSError as e:\n",
        "        if \"file signature not found\" in str(e) or \"Unable to synchronously open\" in str(e):\n",
        "            print(\"ERROR: File is corrupted or incomplete (not a valid HDF5/h5ad).\")\n",
        "            print(\"Re-upload the full discovery_combined.h5ad using the upload cell (file picker), then re-run this cell.\")\n",
        "        else:\n",
        "            raise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run LSTM training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%cd {REPO_ROOT}\n",
        "!python models/lstm_aging_model.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Download results (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "!cd {REPO_ROOT} && zip -r /tmp/lstm_results.zip results/ figures/ 2>/dev/null\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download(\"/tmp/lstm_results.zip\")\n",
        "else:\n",
        "    print(\"Results in\", REPO_ROOT, \"- results/ and figures/\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "scanpy_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}